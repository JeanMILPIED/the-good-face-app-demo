{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2a2a25a",
   "metadata": {},
   "source": [
    "## How to screen a pdf CV ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e16e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required modules\n",
    "from PyPDF2 import PdfReader\n",
    "import re\n",
    "import spacy\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef83cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_pdf(my_pdf):\n",
    "    # creating a pdf reader object\n",
    "    reader = PdfReader(my_pdf)\n",
    "    \n",
    "    output=[]\n",
    "    for i in range(len(reader.pages)):\n",
    "\n",
    "        # getting a specific page from the pdf file\n",
    "        page = reader.pages[i]\n",
    "\n",
    "        # extracting text from page\n",
    "        text = page.extract_text()\n",
    "        output.append(text)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "319eb115",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\xa0 \\xa0\\nCoordonnées\\nwww.linkedin.com/in/\\ncarolinemathius  (LinkedIn)\\nPrincipales compétences\\nAudit\\nHuman Resources\\nNegotiation\\nLanguages\\nAnglais  (Full Professional)\\nItalien  (Full Professional)\\nAlbanais  (Elementary)\\nFrançais  (Native or Bilingual)Caroline Mathius\\nEn formation Data Science\\nAvignon, Provence-Alpes-Côte d’Azur, France\\nRésumé\\nVous êtes sur la page d'un profil atypique, bienvenue !\\nJ'ai 30 ans et un parcours original : Tout commence en 2009,\\nlorsque j’intègre l’IÉSEG School of\\nManagement à Lille, avec un projet professionnel flou mais axé vers\\nl’international. C’est en 1ère année de master que j’ai l’opportunité\\nde partir en ERASMUS en Italie pendant un an, et c'est là que\\nl'aventure commence !\\nDepuis, je bouge, découvre le monde, et différents métiers. Je vous\\nlaisse découvrir mon parcours ...\\nPS : j'ai un fort intérêt pour le Développement Durable !\\nExpérience\\nLeroy Merlin\\n4 ans 5 mois\\nResponsable logistique\\nmars 2020\\xa0-\\xa0Present\\xa0 (3 ans 1 mois)\\nAvignon, Provence-Alpes-Côte d’Azur, France\\nResponsable de rayon\\nnovembre 2018\\xa0-\\xa0mars 2020\\xa0 (1 an 5 mois)\\nAvignon, Provence-Alpes-Côte d’Azur, France\\nGROUPE BLACHERE\\nAssistante RH\\njuillet 2018\\xa0-\\xa0octobre 2018\\xa0 (4 mois)\\nChâteaurenard, Provence-Alpes-Côte d’Azur, France\\nChargée de la déclaration des accidents de travail\\nDecathlon Exchange\\nCustomer Happiness  Coordinator\\n\\xa0 Page 1 of 4\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_pdf('Profile.pdf')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f5e610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(my_text):\n",
    "    \n",
    "    cv_feat_dict={}\n",
    "\n",
    "    cv_feat_dict['page_numbers']=len(my_text)\n",
    "    \n",
    "    my_text='\\n'.join(my_text)\n",
    "    \n",
    "    cv_feat_dict['line_numbers']=my_text.count('\\n')\n",
    "    \n",
    "    my_text_ok=my_text.replace('\\n',' ')\n",
    "    my_text_ok=re.sub(r' +', ' ', my_text_ok)\n",
    "    \n",
    "    #count_1\n",
    "    count_1=len([1 for my_word in my_text_ok.split() if len(my_word)==1])\n",
    "    pc_1=count_1/len(my_text_ok.split())\n",
    "    if pc_1>0.5:\n",
    "        my_text_ok=my_text_ok.replace(' ','')\n",
    "\n",
    "    cv_feat_dict['word_numbers']=len([s for s in re.split(\"[() ,|;\\W]+\", my_text_ok)])\n",
    "    cv_feat_dict['unique_upper_words']=list({i for i in [my_word for my_word in my_text_ok.split() if my_word.isupper()]})\n",
    "\n",
    "    #get name\n",
    "    match_name= re.search(\"[A-Z][a-z]+,?\\s+(?:[A-Z][a-z]*\\.?\\s*)?[A-Z][a-z]\",my_text)\n",
    "    if match_name:\n",
    "        cv_feat_dict['name']=match_name.group()\n",
    "    else:\n",
    "        cv_feat_dict['name']='name not found'\n",
    "    \n",
    "    my_text=my_text_ok.lower()\n",
    "\n",
    "    #remove accents\n",
    "    repl = str.maketrans(\"àâéèêëûôöïç\",\"aaeeeeuooic\")\n",
    "    my_text_ok=my_text.translate(repl)\n",
    "    \n",
    "\n",
    "    # get email\n",
    "    match_email= re.search('[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+',my_text_ok)\n",
    "    if match_email:\n",
    "        cv_feat_dict['email']=match_email.group()\n",
    "    else:\n",
    "        cv_feat_dict['email']='email not found'\n",
    "\n",
    "    # get phone number\n",
    "    match_fr_phone= re.search('(?:(?:\\+|00)33[\\s.-]{0,3}(?:\\(0\\)[\\s.-]{0,3})?|0)[1-9](?:(?:[\\s.-]?\\d{2}){4}|\\d{2}(?:[\\s.-]?\\d{3}){2})',my_text_ok)\n",
    "    if match_fr_phone:\n",
    "        cv_feat_dict['french_phone']=match_fr_phone.group()\n",
    "    else:\n",
    "        cv_feat_dict['french_phone']='french phone not found'\n",
    "        \n",
    "    match_any_phone= re.search('[\\+]?[\\(]?[0-9]{2,3}[)]?[-\\s\\.]?[0-9]{2,3}[-\\s\\.]?[0-9]{3,6}[-\\s\\.]?[0-9]{3,6}',my_text_ok)\n",
    "    if match_any_phone:\n",
    "        cv_feat_dict['other_phone']=match_any_phone.group()\n",
    "    else:\n",
    "        cv_feat_dict['other_phone']='other phone not found'\n",
    "\n",
    "    # get github account\n",
    "    if 'github' in my_text_ok:\n",
    "        cv_feat_dict['has_github']='github'\n",
    "        match_github= re.search('https://github.com+[/a-zA-Z0-9]+',my_text_ok)\n",
    "        if match_github:\n",
    "            cv_feat_dict['github_account']=match_github.group()\n",
    "        else:\n",
    "            cv_feat_dict['github_account']='github account not found'\n",
    "    else:\n",
    "        cv_feat_dict['has_github']='github not mentionned'\n",
    "        cv_feat_dict['github_account']='github account not found'\n",
    "\n",
    "    # get linkedin account\n",
    "    if 'linkedin' in my_text_ok:\n",
    "        cv_feat_dict['has_linkedin']='linkedin'\n",
    "    else:\n",
    "        cv_feat_dict['has_linkedin']='linkedin not mentionned'\n",
    "\n",
    "    #count key words from a competence list\n",
    "    list_keycomp=['ia ','ai ','data','datascience','data scienc','datascient','data eng','python',' r ','sql','docker','cloud','aws', 'azure','ml', 'algorithm', 'algo','statisti','keras','pytorch','machine learning','tensorflow','opencv','computer vision','pandas','numpy','nlp', 'dl ', 'deeplearning','deep learn','neural net','neurone','time serie']\n",
    "    cv_feat_dict['the_data_comp']=[my_comp for my_comp in list_keycomp if my_comp in my_text_ok]\n",
    "\n",
    "    #count key words from a diploma list\n",
    "    list_keydiploma=['phd','docteur','master','iut','dut','ingenie','msc','bac','license','maitrise','master2', 'ecole','école','superieu','reconvers']\n",
    "    cv_feat_dict['the_data_diploma']=[my_dipl for my_dipl in list_keydiploma if my_dipl in my_text_ok]\n",
    "    \n",
    "    #count key words from a language list\n",
    "    list_keylang=['francais','french','anglais','english','allemand','german','indien','indian','arabe','arabic','espagnol','spanish','italien','italian','chinois','chinese']\n",
    "    cv_feat_dict['the_data_lang']=[my_lang for my_lang in list_keylang if my_lang in my_text_ok]\n",
    "    \n",
    "    #count manager experience\n",
    "    list_keymgt=['management','manageur','manager','team','equipe','mgr ']\n",
    "    cv_feat_dict['the_data_mgt']=[my_mgt for my_mgt in list_keymgt if my_mgt in my_text_ok]\n",
    "                \n",
    "    return my_text_ok, cv_feat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3efc724",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_text_ok,feat=get_features(get_text_pdf('Profile.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd7a2a80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\xa0 \\xa0 coordonnees www.linkedin.com/in/ carolinemathius (linkedin) principales competences audit human resources negotiation languages anglais (full professional) italien (full professional) albanais (elementary) francais (native or bilingual)caroline mathius en formation data science avignon, provence-alpes-cote d’azur, france resume vous etes sur la page d\\'un profil atypique, bienvenue ! j\\'ai 30 ans et un parcours original : tout commence en 2009, lorsque j’integre l’ieseg school of management a lille, avec un projet professionnel flou mais axe vers l’international. c’est en 1ere annee de master que j’ai l’opportunite de partir en erasmus en italie pendant un an, et c\\'est la que l\\'aventure commence ! depuis, je bouge, decouvre le monde, et differents metiers. je vous laisse decouvrir mon parcours ... ps : j\\'ai un fort interet pour le developpement durable ! experience leroy merlin 4 ans 5 mois responsable logistique mars 2020\\xa0-\\xa0present\\xa0 (3 ans 1 mois) avignon, provence-alpes-cote d’azur, france responsable de rayon novembre 2018\\xa0-\\xa0mars 2020\\xa0 (1 an 5 mois) avignon, provence-alpes-cote d’azur, france groupe blachere assistante rh juillet 2018\\xa0-\\xa0octobre 2018\\xa0 (4 mois) chateaurenard, provence-alpes-cote d’azur, france chargee de la declaration des accidents de travail decathlon exchange customer happiness coordinator \\xa0 page 1 of 4 \\xa0 \\xa0 fevrier 2017\\xa0-\\xa0septembre 2017\\xa0 (8 mois) villeneuve-d’ascq, nord-pas-de-calais, france - gestion des formations et service client (accueil et administration) - comptabilite - facturation prestataires - responsable rse/developpement durable - projets de communication - support technique des webinars (animation du chat et gestion du live streaming) mazars auditrice financiere junior septembre 2016\\xa0-\\xa0janvier 2017\\xa0 (5 mois) region de lille, france assistante de niveau 1 deloitte albania and kosova assistante auditeur aout 2015\\xa0-\\xa0aout 2016\\xa0 (1 an 1 mois) tirana deloitte albania sh.p.k, tirana (albanie) - membre a distance de deux equipes d\\'audit basees en italie (travaillant a monaco pour le bureau de genova): assistance pour les diverses activites d\\'audit - ita gaap, ifrs - secteurs: transport maritime, croisieres de luxe, grande distribution selenice bitumi assistante marketing mars 2015\\xa0-\\xa0juillet 2015\\xa0 (5 mois) tirana, albanie - reprise de contact avec d\\'anciens clients; - elaboration et gestion d\\'un fichier de suivi des clients - activites de back-office - premier contact avec prospects leroy merlin italie stagiaire responsable rh magasin fevrier 2014\\xa0-\\xa0aout 2014\\xa0 (7 mois) lissone - processus de recrutement (screening des cv, convocation des candidats, entretiens d\\'embauche) \\xa0 page 2 of 4 \\xa0 \\xa0 - administration des ressources humaines (paiement, releve des absences et conges, logiciel utilise : zucchetti, suivi des visites medicales et autres taches administratives de rh) - planification des formations, etude des besoins en formation - communication interne - membre du green group (association au sein du point de vente regroupant des employes soucieux du respect de l\\'environnement) groupe chantelle stage assistante chef de produit marketing juin 2013\\xa0-\\xa0janvier 2014\\xa0 (8 mois) milano - gestion et realisation des supports de communication - contact avec les fournisseurs, les services presse, les relations publiques - gestion des differentes collections d\\'echantillons (envois aux services \"presse\" par exemple) - activites de back-office - gestion de la version italienne du site web et autres activites de communication (exemple: page facebook des marques) bold boys responsable developpement commercial mai 2012\\xa0-\\xa0juillet 2012\\xa0 (3 mois) lille responsable collection ss/13 ; confection du lookbook de la saison printemps-ete 2013 ; recherche d\\'agents commerciaux sur la region idl, en belgique ; preparation de salons (who\\'s next a paris, scoop a londres, ubifrance a barcelone) auchan hotesse de caisse juin 2010\\xa0-\\xa0mai 2012\\xa0 (2 ans) cambrai, france hotesse de caisse (contrat vacances et jours feries) galeria inno vendeuse mode femme juin 2011\\xa0-\\xa0juillet 2011\\xa0 (2 mois) bruxelles \\xa0 page 3 of 4 \\xa0 \\xa0 conseillere de vente en pret-a-porter feminin ; re-assortiment ; preparation des soldes ; caisse. formation jedha bootcamp data science \\xa0·\\xa0(decembre 2022) ieseg school of management master en management programme grande ecole,\\xa0international management \\xa0·\\xa0(2009\\xa0-\\xa02014) universita degli studi di bergamo international business, management, marketing, hrm \\xa0·\\xa0(2012\\xa0-\\xa02013) lycee notre-dame de grace cambrai baccalaureat scientifique\\xa0 \\xa0·\\xa0(2006\\xa0-\\xa02009) \\xa0 page 4 of 4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a54e95b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_numbers': 4,\n",
       " 'line_numbers': 133,\n",
       " 'word_numbers': 666,\n",
       " 'unique_upper_words': ['ITA',\n",
       "  'LEROY',\n",
       "  'MERLIN',\n",
       "  'IÉSEG',\n",
       "  'IDL,',\n",
       "  'GROUPE',\n",
       "  'CV,',\n",
       "  'IFRS',\n",
       "  'SS/13',\n",
       "  'BLACHERE',\n",
       "  'ERASMUS',\n",
       "  'RH)',\n",
       "  'RH',\n",
       "  'GAAP,',\n",
       "  'PS',\n",
       "  'HRM'],\n",
       " 'name': 'Audit\\nHuman Re',\n",
       " 'email': 'email not found',\n",
       " 'french_phone': 'french phone not found',\n",
       " 'other_phone': 'other phone not found',\n",
       " 'has_github': 'github not mentionned',\n",
       " 'github_account': 'github account not found',\n",
       " 'has_linkedin': 'linkedin',\n",
       " 'the_data_comp': ['ia ', 'ai ', 'data', 'data scienc'],\n",
       " 'the_data_diploma': ['master', 'bac', 'ecole'],\n",
       " 'the_data_lang': ['francais', 'anglais', 'italien'],\n",
       " 'the_data_mgt': ['management', 'equipe']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4884ab82",
   "metadata": {},
   "source": [
    "### essai avec Spacy - recherche d'entités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "852d8c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ecf35f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text,feat_cv=get_features(get_text_pdf('Ahmed_Farjallah_CV.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f378981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ahmed farjallah data scientist etudiant en science des donnees enthousiaste et motive a la recherche d'un stage de ﬁn d'etudes qui me permettra d'utiliser et d'ameliorer les competences et les forces que j'ai acquises en tant qu'etudiant. ahmed.farjallah@esprit.tn +216 23 277 171 tunis, tunisie ahmedfarjallah.webipie.me/ linkedin.com/in/ahmed-farjallah- datascientist competences python r keras tensorﬂow opencv flask django powerbi git azure hadoop plotly dash nlp time series analysis dl ml langues arabe anglais francais interets jeu d'echec lire cinema sport education ingenierie informatique specialisee en datascience ecole superieure privee d'ingenierie et de technologies 09/2018 - 01/2023 , tunis,tunisia experience professionnelle data scientist avaxia consulting group 07/2022 - 09/2022 , tunis,tunisie analyser de l'ensemble des donnees a l'aide de seaborn, matplotlib, et plotly. utiliser la bibliotheque de tableaux de bord pour aﬃcher les resultats de l'analyse dans un tableau de bord pour le suivi. prevoir la consommation future a l'aide des modeles facebook prophet, lstm et arima, et evaluer le resultat. data scientist avaxia consulting group 06/2022 - 07/2022 , tunis,tunisie en utilisant opencv, preparez l'image de donnees en supprimant le bruit, en la convertissant en noir et blanc et en la segmentant. entraîner un modele sur les donnees en utilisant l'api azure form recognizer pour identiﬁer et determiner la disposition d'un tableau dans un formulaire. permet d'extraire la presentation et le contenu des tableaux du ﬁchier json dans une feuille excel en utilisant la bibliotheque openpyxl. data scientist esprit s'associe a une banque 12/2021 - 05/2022 , tuni,tunisie scraping pour collecter les donnees et decoupage automatique des cheques. generer de fausses signatures pour les nouveaux clients. entraîner le modele a veriﬁer si le montant en lettres est le meme que le montant en chiffres, ainsi que l'authenticite de la signature. cybersecurity oddo bhf 07/2021 - 09/2021 , tunis,tunisie la mise en place d'un repertoire actif dans un environnement windows permet aux administrateurs d'attribuer et d'appliquer des politiques ainsi que d'installer des mises a jour cruciales. appliquer des attaques a l'aide de bloodhound et infection monkey pour tester le niveau de securite du reseau, puis renforcez le reseau en fonction des normes de reference du cis. projets academique predictdo (09/2021 - 12/202) predicter la probabilite de defaut des clients de cartes de credit (paiement du mois procahin). big data projet (11/2021 - 12/2021) recuperer les donnees avec spark streaming et effectuer le traitement modelisation de la consommation d'electricite des menages extraction de tableaux vers une feuille excel automatisation de la veriﬁcation des cheques bancaires creation d'un active directory \n",
      "{'page_numbers': 1, 'line_numbers': 99, 'word_numbers': 456, 'unique_upper_words': ['EDUCATION', 'COMPÉTENCES', 'DL', 'R', 'LSTM', 'BHF', 'ACADEMIQUE', 'EXPÉRIENCE', 'PROJETS', 'CIS.', 'INTÉRÊTS', 'ML', 'ESPRIT', 'ODDO', 'ARIMA,', 'LANGUES', 'NLP', 'PROFESSIONNELLE'], 'name': 'Ahmed Farjallah \\nDa', 'email': 'ahmed.farjallah@esprit.tn', 'french_phone': 'french phone not found', 'other_phone': '+216 23 277 171', 'has_github': 'github not mentionned', 'github_account': 'github account not found', 'has_linkedin': 'linkedin', 'the_data_comp': ['ia ', 'ai ', 'data', 'datascience', 'datascient', 'python', ' r ', 'azure', 'ml', 'keras', 'opencv', 'nlp', 'dl ', 'time serie'], 'the_data_diploma': ['ingenie', 'ecole', 'superieu'], 'the_data_lang': ['francais', 'anglais', 'arabe'], 'the_data_mgt': []}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text), print(feat_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6261561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ahmed farjallah data scientist PER\n",
      "ahmed.farjallah@esprit.tn LOC\n",
      "tunisie LOC\n",
      "python r keras tensorﬂow MISC\n",
      "opencv flask django powerbi git azure hadoop ORG\n",
      "time series analysis dl ml langues arabe anglais francais MISC\n",
      "tunis LOC\n",
      "avaxia consulting group 07/2022 PER\n",
      "tunis LOC\n",
      "tunisie LOC\n",
      "seaborn PER\n",
      "matplotlib MISC\n",
      "data scientist avaxia consulting group MISC\n",
      "tunis LOC\n",
      "tunisie LOC\n",
      "data scientist MISC\n",
      "tuni LOC\n",
      "tunisie LOC\n",
      "cybersecurity MISC\n",
      "tunis LOC\n",
      "tunisie LOC\n",
      "windows MISC\n",
      "cis ORG\n",
      "spark streaming PER\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "372a5b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIENCE ORG\n",
      "Paris LOC\n",
      "Réalisation des études OA ORG\n",
      "Eurocodes MISC\n",
      "DQE MISC\n",
      "l’ LOC\n",
      "Suivi ORG\n",
      "d’ MISC\n",
      "VISA MISC\n",
      "d’ MISC\n",
      "d’ MISC\n",
      "l’autoroute MISC\n",
      "A3 LOC\n",
      "Préparation ORG\n",
      "Conduite PER\n",
      "EXE ORG\n",
      "l’ LOC\n",
      "Janvier PER\n",
      "Méthodes probabilistes MISC\n",
      "Polytechnique Montréal ORG\n",
      "Méthodes LOC\n",
      "Méthodes LOC\n",
      "l’ LOC\n",
      "l’ LOC\n",
      "Monte-Carlo LOC\n",
      "Janvier 2018 MISC\n",
      "Analyse de \n",
      "Structures MISC\n",
      "Conception Béton MISC\n",
      "d’ MISC\n",
      "Présentation des TD en Analyse de structures MISC\n",
      "l’ LOC\n",
      "EF ORG\n",
      "Présentation des TD MISC\n",
      "Conception Béton Armé MISC\n",
      "FORMATION ORG\n",
      "Applied MSc in PER\n",
      "Science & Artificial \n",
      " ORG\n",
      "France LOC\n",
      "Polytechnique Montréal   \n",
      "Maîtrise ORG\n",
      "Spécialisation PER\n",
      "Montréal LOC\n",
      "Canada LOC\n",
      "Métiers ParisTech ORG\n",
      "Formation MISC\n",
      "CPGE PSI ORG\n",
      "Lycée Joffre LOC\n",
      "Montpellier LOC\n",
      "France LOC\n",
      "Solides PER\n",
      "Connaissances en Machine learning \n",
      "appliqué MISC\n",
      "Structural Health Monitoring ORG\n",
      "Software \n",
      "Programmation ORG\n",
      "Python MISC\n",
      "VBA MISC\n",
      "Structure: Sofisitk MISC\n",
      "ST1 MISC\n",
      "Robot SA LOC\n",
      "Dessin LOC\n",
      "AutoCAD MISC\n",
      "Revit PER\n",
      "Pack office MISC\n",
      "MS Projects MISC\n",
      "Anglais MISC\n",
      "Espagnol MISC\n",
      "B1 MISC\n",
      "Littérature Américaine MISC\n",
      "Architecture \n",
      " \n",
      "Engagements MISC\n",
      "l’ LOC\n",
      "Sport LOC\n",
      "Planche PER\n",
      "Tennis   PER\n",
      "Louis FLANDIN \n",
      " PER\n",
      "d’ MISC\n",
      "j’ MISC\n",
      "Machine Learning MISC\n",
      "MSc LOC\n",
      "Data Science MISC\n",
      "Morère LOC\n",
      "Paris LOC\n"
     ]
    }
   ],
   "source": [
    "text = get_text_pdf('CV - Flandin.pdf')[0]\n",
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0591e8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "# initialize matcher with a vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "def extract_name(resume_text):\n",
    "    nlp_text = nlp(resume_text)\n",
    "    \n",
    "    # First name and Last name are always Proper Nouns\n",
    "    pattern = [[{'ENT_TYPE': 'PER'},{'ENT_TYPE': 'PER'}]]\n",
    "    \n",
    "    matcher.add('NAME',pattern)\n",
    "    \n",
    "    matches = matcher(nlp_text)\n",
    "    \n",
    "    for match_id, start, end in matches:\n",
    "        span = nlp_text[start:end]\n",
    "        name=span.text.split()\n",
    "        if len(name)>1:\n",
    "            match_name= re.search(\"^([a-zA-Z]{2,}\\s[a-zA-Z]{3,}'?-?[a-zA-Z]{2,}\\s?([a-zA-Z]{3,})?)\",span.text)\n",
    "            if match_name:\n",
    "                the_name=span.text\n",
    "            else:\n",
    "                the_name='not found'\n",
    "        else:\n",
    "            the_name='not found'\n",
    "    return the_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f307078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_cv(my_text):\n",
    "    \n",
    "    cv_feat_dict={}\n",
    "\n",
    "    cv_feat_dict['page_numbers']=len(my_text)\n",
    "    \n",
    "    my_text='\\n'.join(my_text)\n",
    "    \n",
    "    cv_feat_dict['line_numbers']=my_text.count('\\n')\n",
    "    \n",
    "    my_text_ok=my_text.replace('\\n',' ')\n",
    "    my_text_ok=re.sub(r' +', ' ', my_text_ok)\n",
    "    \n",
    "    #count_1\n",
    "    count_1=len([1 for my_word in my_text_ok.split() if len(my_word)==1])\n",
    "    pc_1=count_1/len(my_text_ok.split())\n",
    "    if pc_1>0.5:\n",
    "        my_text_ok=my_text_ok.replace(' ','')\n",
    "\n",
    "    cv_feat_dict['word_numbers']=len([s for s in re.split(\"[() ,|;\\W]+\", my_text_ok)])\n",
    "    cv_feat_dict['unique_upper_words']=list({i for i in [my_word for my_word in my_text_ok.split() if my_word.isupper()]})\n",
    "\n",
    "    #get name\n",
    "    cv_feat_dict['name'] = extract_name(my_text_ok)\n",
    "    \n",
    "    my_text=my_text_ok.lower()\n",
    "\n",
    "    #remove accents\n",
    "    repl = str.maketrans(\"àâéèêëûôöïç\",\"aaeeeeuooic\")\n",
    "    my_text_ok=my_text.translate(repl)\n",
    "    \n",
    "\n",
    "    # get email\n",
    "    match_email= re.search('[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+',my_text_ok)\n",
    "    if match_email:\n",
    "        cv_feat_dict['email']=match_email.group()\n",
    "    else:\n",
    "        cv_feat_dict['email']='email not found'\n",
    "\n",
    "    # get phone number\n",
    "    match_fr_phone= re.search('(?:(?:\\+|00)33[\\s.-]{0,3}(?:\\(0\\)[\\s.-]{0,3})?|0)[1-9](?:(?:[\\s.-]?\\d{2}){4}|\\d{2}(?:[\\s.-]?\\d{3}){2})',my_text_ok)\n",
    "    if match_fr_phone:\n",
    "        cv_feat_dict['french_phone']=match_fr_phone.group()\n",
    "    else:\n",
    "        cv_feat_dict['french_phone']='french phone not found'\n",
    "        \n",
    "    match_any_phone= re.search('[\\+]?[\\(]?[0-9]{2,3}[)]?[-\\s\\.]?[0-9]{2,3}[-\\s\\.]?[0-9]{3,6}[-\\s\\.]?[0-9]{3,6}',my_text_ok)\n",
    "    if match_any_phone:\n",
    "        cv_feat_dict['other_phone']=match_any_phone.group()\n",
    "    else:\n",
    "        cv_feat_dict['other_phone']='other phone not found'\n",
    "\n",
    "    # get github account\n",
    "    if 'github' in my_text_ok:\n",
    "        cv_feat_dict['has_github']='github'\n",
    "        match_github= re.search('https://github.com+[/a-zA-Z0-9]+',my_text_ok)\n",
    "        if match_github:\n",
    "            cv_feat_dict['github_account']=match_github.group()\n",
    "        else:\n",
    "            cv_feat_dict['github_account']='github account not found'\n",
    "    else:\n",
    "        cv_feat_dict['has_github']='github not mentionned'\n",
    "        cv_feat_dict['github_account']='github account not found'\n",
    "\n",
    "    # get linkedin account\n",
    "    if 'linkedin' in my_text_ok:\n",
    "        cv_feat_dict['has_linkedin']='linkedin'\n",
    "    else:\n",
    "        cv_feat_dict['has_linkedin']='linkedin not mentionned'\n",
    "\n",
    "    #count key words from a competence list\n",
    "    list_keycomp=['ia ','ai ','data','datascience','data scienc','datascient','data eng','python',' r ','sql','docker','cloud','aws', 'azure','ml', 'algorithm', 'algo','statisti','keras','pytorch','machine learning','tensorflow','opencv','computer vision','pandas','numpy','nlp', 'dl ', 'deeplearning','deep learn','neural net','neurone','time serie']\n",
    "    cv_feat_dict['the_data_comp']=[my_comp for my_comp in list_keycomp if my_comp in my_text_ok]\n",
    "\n",
    "    #count key words from a diploma list\n",
    "    list_keydiploma=['phd','docteur','master','iut','dut','ingenie','msc','bac','license','maitrise','master2', 'ecole','école','superieu','reconvers']\n",
    "    cv_feat_dict['the_data_diploma']=[my_dipl for my_dipl in list_keydiploma if my_dipl in my_text_ok]\n",
    "    \n",
    "    #count key words from a language list\n",
    "    list_keylang=['francais','french','anglais','english','allemand','german','indien','indian','arabe','arabic','espagnol','spanish','italien','italian','chinois','chinese']\n",
    "    cv_feat_dict['the_data_lang']=[my_lang for my_lang in list_keylang if my_lang in my_text_ok]\n",
    "    \n",
    "    #count manager experience\n",
    "    list_keymgt=['management','manageur','manager','team','equipe','mgr ']\n",
    "    cv_feat_dict['the_data_mgt']=[my_mgt for my_mgt in list_keymgt if my_mgt in my_text_ok]\n",
    "                \n",
    "    return my_text_ok, cv_feat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f79b8d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text,feat_cv=get_features_cv(get_text_pdf('CV - Flandin.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ace0fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_numbers': 1,\n",
       " 'line_numbers': 113,\n",
       " 'word_numbers': 481,\n",
       " 'unique_upper_words': ['TD',\n",
       "  'EXPERIENCE',\n",
       "  'ATOUTS',\n",
       "  'FORMATION',\n",
       "  'ARTELIA',\n",
       "  'MS',\n",
       "  'CPGE',\n",
       "  'A3',\n",
       "  'ST1;',\n",
       "  '(VISA),',\n",
       "  'B1',\n",
       "  'OA',\n",
       "  'SA;',\n",
       "  'B2',\n",
       "  'CAO',\n",
       "  'INTERETS',\n",
       "  'FLANDIN',\n",
       "  'DQE,',\n",
       "  'TOEIC',\n",
       "  'EF',\n",
       "  'PSI*',\n",
       "  'VBA'],\n",
       " 'name': 'Louis FLANDIN',\n",
       " 'email': 'louis.flandin19@gmail.com',\n",
       " 'french_phone': '06 75 83 48 31',\n",
       " 'other_phone': 'other phone not found',\n",
       " 'has_github': 'github not mentionned',\n",
       " 'github_account': 'github account not found',\n",
       " 'has_linkedin': 'linkedin not mentionned',\n",
       " 'the_data_comp': ['ia ',\n",
       "  'ai ',\n",
       "  'data',\n",
       "  'data scienc',\n",
       "  'python',\n",
       "  'machine learning'],\n",
       " 'the_data_diploma': ['ingenie', 'msc', 'reconvers'],\n",
       " 'the_data_lang': ['anglais', 'espagnol'],\n",
       " 'the_data_mgt': []}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bd820c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
